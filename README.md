# LATAM DevSecOps/SRE Challenge Rodrigo ValdÃ©s

[![Deploy Status](https://github.com/rodvaldes/latam-devops-challenge/actions/workflows/deploy.yml/badge.svg)](https://github.com/rodvaldes/latam-devops-challenge/actions/workflows/deploy.yml)


Este repositorio contiene la soluciÃ³n al desafÃ­o tÃ©cnico de LATAM Airlines. El objetivo es construir un sistema en la nube que permita ingestar, almacenar y exponer datos mediante IaC, CI/CD y una arquitectura resiliente.

---

## ðŸ“¦ Estructura del Proyecto

```bash
.
â”œâ”€â”€ app/ # API HTTP con FastAPI (exposiciÃ³n de datos desde BigQuery)
â”œâ”€â”€ publisher/ # Scripts para simular la publicaciÃ³n de eventos a Pub/Sub
â”œâ”€â”€ tests/ # Prueba de integraciÃ³n de la API
â”œâ”€â”€ iac/terraform/ # Infraestructura como cÃ³digo (opcional)
â”œâ”€â”€ requirements.txt # Dependencias del proyecto
â””â”€â”€ README.md
```
## Parte 1: Infraestructura e IaC

La infraestructura fue definida completamente con **Terraform**, permitiendo reproducibilidad y control de cambios. Se desplegaron los siguientes componentes en Google Cloud Platform:

- **Pub/Sub**: se creÃ³ un tÃ³pico para simular eventos en tiempo real.
- **BigQuery**: se configurÃ³ un dataset y una tabla para almacenar los eventos.
- **Service Accounts**: con permisos mÃ­nimos para ejecutar los componentes.
- **Cloud Run**: se dejÃ³ provisionado el entorno para alojar la API HTTP.
- **Remote Backend**: el estado de Terraform se almacenÃ³ en un bucket de GCS dedicado.

La estructura modular del cÃ³digo permite separar ambientes y reutilizar componentes.

> El directorio `iac/terraform/` contiene los archivos `main.tf`, `variables.tf`, y `outputs.tf` que definen esta infraestructura.
---

## Parte 2: Aplicaciones y CI/CD

- La API HTTP fue desarrollada con **FastAPI** y desplegada exitosamente en **Cloud Run**.
- Se conecta a **BigQuery** para exponer los datos ingresados previamente vÃ­a Pub/Sub.
- Se incluye una **prueba de integraciÃ³n** (`tests/test_api.py`) que valida que el endpoint `/datos` responde correctamente.
- El despliegue fue realizado inicialmente de forma manual; se deja planteado un pipeline GitHub Actions para futuras automatizaciones.

---

## ðŸ§  Parte 3: Pruebas y calidad

- Se implementÃ³ una prueba de integraciÃ³n bÃ¡sica que:
  - Verifica el cÃ³digo de estado 200.
  - Confirma que la respuesta es una lista JSON no vacÃ­a con los campos `flight_id`, `status`, `timestamp`.

### Otras pruebas sugeridas (no implementadas):

- Test de carga al endpoint `/datos`.
- ValidaciÃ³n de datos almacenados en BigQuery despuÃ©s de recibir mensajes Pub/Sub.
- SimulaciÃ³n de errores en la base de datos para probar resiliencia de la API.

---

## Parte 4: MÃ©tricas y monitoreo

### MÃ©tricas crÃ­ticas propuestas:

1. **Tasa de mensajes recibidos por Pub/Sub** (ingesta)
2. **Tiempo de respuesta del endpoint `/datos`**
3. **Errores 5xx o latencias elevadas en Cloud Run**

### Herramienta sugerida:

- **Google Cloud Monitoring + Grafana**
  - Dashboards con:
    - NÃºmero de mensajes procesados
    - Errores por minuto
    - Tiempo promedio de respuesta

### Escalamiento:

- Al escalar a mÃºltiples servicios similares, se recomienda agrupar mÃ©tricas por etiqueta (`project`, `dataset`, `service`) y usar vistas agregadas.

---

## Parte 5: Alertas y confiabilidad (opcional)

### Umbrales sugeridos:

- Tiempo de respuesta > 1.5s en promedio â†’ alerta
- Error rate > 1% sostenido â†’ alerta al canal SRE
- Sin mensajes en Pub/Sub por mÃ¡s de 10 minutos â†’ alerta

### SLIs/SLOs propuestos:

| Servicio      | SLI                        | SLO                             |
|---------------|----------------------------|----------------------------------|
| API HTTP      | 99% de respuestas < 800ms  | 99.9% disponibilidad mensual     |
| Ingesta Pub/Sub | 99.5% de mensajes insertados correctamente | <0.5% fallos procesados al dÃ­a |



# Arquitectura de Sistema

Este sistema sigue un patrÃ³n event-driven. Un publicador simula eventos de vuelos y los envÃ­a a un tÃ³pico Pub/Sub. Un suscriptor (Python) escucha y guarda los datos en BigQuery. Luego, una API FastAPI (en Cloud Run) expone los datos en formato JSON.


+-------------------+
|  Simulador/       |
|  Publicador de    |
|  eventos (Python) |
+---------+---------+
          |
          | JSON
          v
+---------+---------+
|     Pub/Sub       |
| (Topic: flight-events) |
+---------+---------+
          |
          | Trigger
          v
+------------------------+
| Suscriptor Python      |
| (script local)         |
| - Recibe mensaje       |
| - Inserta en BigQuery  |
+----------+-------------+
           |
           | INSERT
           v
+------------------------+
| BigQuery               |
| - Dataset: flights     |
| - Tabla: flight_status |
+----------+-------------+
           |
           | SELECT
           v
+--------------------------+
| API HTTP en FastAPI      |
| (Desplegada en Cloud Run)|
+----------+---------------+
           |
           | JSON Response
           v
+-------------------+
|    Usuario final  |
|  (Browser / curl) |
+-------------------+


---

## ðŸš€ CÃ³mo correr el proyecto

```bash
# Clonar el repositorio
git clone https://github.com/tu_usuario/latam-devops-challenge.git
cd latam-devops-challenge

# Crear y activar entorno virtual (Python 3.11 recomendado)
python3.11 -m venv venv
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt

# Correr la API localmente
uvicorn app.main:app --reload

# Ejecutar pruebas
pytest tests/test_api.py

# Publicar mensaje a Pub/Sub (opcional, ver publisher/publisher.py)
python publisher/publisher.py

#Â Supuestos y mejoras posibles

* Se asume un formato de datos simple (flight_id, status, timestamp).

* Se deja como mejora implementar procesamiento batch con Apache Beam.

* Se puede integrar mÃ¡s monitoreo con Prometheus + Grafana.

* Pipeline CI/CD completo con validaciones y despliegue automatizado es parte del roadmap futuro.

Contacto
Rodrigo ValdÃ©s
[rodrigovaldes@gmail.com]
https://github.com/rodvaldes
